{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U accelerate transformers datasets evaluate jiwer","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-03-20T05:56:23.891548Z","iopub.execute_input":"2024-03-20T05:56:23.891903Z","iopub.status.idle":"2024-03-20T05:57:03.430404Z","shell.execute_reply.started":"2024-03-20T05:56:23.891873Z","shell.execute_reply":"2024-03-20T05:57:03.429243Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\nCollecting accelerate\n  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\nCollecting transformers\n  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting datasets\n  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting jiwer\n  Downloading jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nCollecting pyarrow>=12.0.0 (from datasets)\n  Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nCollecting pyarrow-hotfix (from datasets)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.7)\nRequirement already satisfied: rapidfuzz<4,>=3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (3.6.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiwer-3.0.3-py3-none-any.whl (21 kB)\nDownloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, pyarrow, jiwer, accelerate, transformers, datasets, evaluate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 11.0.0\n    Uninstalling pyarrow-11.0.0:\n      Successfully uninstalled pyarrow-11.0.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.27.2\n    Uninstalling accelerate-0.27.2:\n      Successfully uninstalled accelerate-0.27.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.1\n    Uninstalling transformers-4.38.1:\n      Successfully uninstalled transformers-4.38.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.28.0 datasets-2.18.0 evaluate-0.4.1 jiwer-3.0.3 pyarrow-15.0.2 pyarrow-hotfix-0.6 transformers-4.38.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\nfrom datasets import load_dataset, DatasetDict, Audio\nfrom transformers import (AutoProcessor\n                          , AutoModelForSeq2SeqLM\n                          , Seq2SeqTrainingArguments\n                          , Seq2SeqTrainer\n                          , WhisperForConditionalGeneration)\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\nimport evaluate\nfrom transformers.models.whisper.english_normalizer import BasicTextNormalizer\nfrom functools import partial\n\nfrom huggingface_hub import notebook_login","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-20T05:57:03.432477Z","iopub.execute_input":"2024-03-20T05:57:03.432781Z","iopub.status.idle":"2024-03-20T05:57:22.314071Z","shell.execute_reply.started":"2024-03-20T05:57:03.432754Z","shell.execute_reply":"2024-03-20T05:57:22.313255Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-20 05:57:11.432311: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-20 05:57:11.432443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-20 05:57:11.576258: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"notebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:22.315331Z","iopub.execute_input":"2024-03-20T05:57:22.315955Z","iopub.status.idle":"2024-03-20T05:57:22.340325Z","shell.execute_reply.started":"2024-03-20T05:57:22.315926Z","shell.execute_reply":"2024-03-20T05:57:22.339051Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"763eef41ef8d4ee79fae56d062696be2"}},"metadata":{}}]},{"cell_type":"code","source":"data = load_dataset(\"PolyAI/minds14\", \"en-US\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:22.342609Z","iopub.execute_input":"2024-03-20T05:57:22.342936Z","iopub.status.idle":"2024-03-20T05:57:42.936750Z","shell.execute_reply.started":"2024-03-20T05:57:22.342911Z","shell.execute_reply":"2024-03-20T05:57:42.935920Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf839ff38c9d4134abdf2fd8fb9bff66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52e2375dbfc64366997ee7ae4c699d02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb0a874b619d4e64a94f60058401a94f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beef90e9efaa4e93aaa6cc44a0aa73de"}},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:42.938057Z","iopub.execute_input":"2024-03-20T05:57:42.938472Z","iopub.status.idle":"2024-03-20T05:57:42.946895Z","shell.execute_reply.started":"2024-03-20T05:57:42.938424Z","shell.execute_reply":"2024-03-20T05:57:42.945894Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n        num_rows: 563\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"data = data.select_columns([\"audio\", \"transcription\"])","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:42.948613Z","iopub.execute_input":"2024-03-20T05:57:42.948973Z","iopub.status.idle":"2024-03-20T05:57:42.970703Z","shell.execute_reply.started":"2024-03-20T05:57:42.948945Z","shell.execute_reply":"2024-03-20T05:57:42.969827Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_size = 450\ndata = data[\"train\"].train_test_split(shuffle=False\n                                  , train_size=train_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:42.972278Z","iopub.execute_input":"2024-03-20T05:57:42.972681Z","iopub.status.idle":"2024-03-20T05:57:42.985510Z","shell.execute_reply.started":"2024-03-20T05:57:42.972644Z","shell.execute_reply":"2024-03-20T05:57:42.984618Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:42.986922Z","iopub.execute_input":"2024-03-20T05:57:42.987888Z","iopub.status.idle":"2024-03-20T05:57:42.994177Z","shell.execute_reply.started":"2024-03-20T05:57:42.987836Z","shell.execute_reply":"2024-03-20T05:57:42.993159Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['audio', 'transcription'],\n        num_rows: 450\n    })\n    test: Dataset({\n        features: ['audio', 'transcription'],\n        num_rows: 113\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"model_name = 'openai/whisper-tiny'","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:42.995296Z","iopub.execute_input":"2024-03-20T05:57:42.995697Z","iopub.status.idle":"2024-03-20T05:57:43.001898Z","shell.execute_reply.started":"2024-03-20T05:57:42.995668Z","shell.execute_reply":"2024-03-20T05:57:43.000923Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"processor = AutoProcessor.from_pretrained(model_name\n                                         , language = 'english'\n                                         , task = 'transcribe')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:43.006488Z","iopub.execute_input":"2024-03-20T05:57:43.007063Z","iopub.status.idle":"2024-03-20T05:57:47.892120Z","shell.execute_reply.started":"2024-03-20T05:57:43.007035Z","shell.execute_reply":"2024-03-20T05:57:47.891338Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"445465437dfb4f2fb1fdd0333a08bccd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee537bda12ff4da4b5f37117c6443778"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9066182558744d50a9ca7e97ba07cfc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f903d8ad7c3e4cdcaad80c913d4bcab5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04906f5d2dc34e7d94218d951cbd6b14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1ea60669e334c22862cbbd83ebc8998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f08efff46c94b8cb48076637bde8bd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbb12eb2664149e09c061493b6a3e0f4"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"data['train'].features","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:47.893216Z","iopub.execute_input":"2024-03-20T05:57:47.893498Z","iopub.status.idle":"2024-03-20T05:57:47.899625Z","shell.execute_reply.started":"2024-03-20T05:57:47.893474Z","shell.execute_reply":"2024-03-20T05:57:47.898673Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'audio': Audio(sampling_rate=8000, mono=True, decode=True, id=None),\n 'transcription': Value(dtype='string', id=None)}"},"metadata":{}}]},{"cell_type":"code","source":"sampling_rate = processor.feature_extractor.sampling_rate\ndata = data.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:47.900825Z","iopub.execute_input":"2024-03-20T05:57:47.901181Z","iopub.status.idle":"2024-03-20T05:57:52.001700Z","shell.execute_reply.started":"2024-03-20T05:57:47.901150Z","shell.execute_reply":"2024-03-20T05:57:52.000977Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(example):\n    audio = example[\"audio\"]\n\n    example = processor(\n        audio=audio[\"array\"],\n        sampling_rate=audio[\"sampling_rate\"],\n        text=example[\"transcription\"],\n    )\n\n    # compute input length of audio sample in seconds\n    example[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:52.002741Z","iopub.execute_input":"2024-03-20T05:57:52.003020Z","iopub.status.idle":"2024-03-20T05:57:52.008821Z","shell.execute_reply.started":"2024-03-20T05:57:52.002995Z","shell.execute_reply":"2024-03-20T05:57:52.007907Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data = data.map(\n    prepare_dataset\n    , remove_columns=data.column_names[\"train\"]\n    , num_proc=1\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:57:52.009950Z","iopub.execute_input":"2024-03-20T05:57:52.010237Z","iopub.status.idle":"2024-03-20T05:58:19.212940Z","shell.execute_reply.started":"2024-03-20T05:57:52.010214Z","shell.execute_reply":"2024-03-20T05:58:19.212010Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e1bbfd88d6043b9bcbe74496d4c91ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44ef411af5be407f8b6c0c3a568e4eec"}},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 30.0\n\ndef is_audio_in_length_range(length):\n    return length < max_input_length","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:58:19.214207Z","iopub.execute_input":"2024-03-20T05:58:19.214831Z","iopub.status.idle":"2024-03-20T05:58:19.219461Z","shell.execute_reply.started":"2024-03-20T05:58:19.214804Z","shell.execute_reply":"2024-03-20T05:58:19.218606Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data[\"train\"] = data[\"train\"].filter(\n    is_audio_in_length_range\n    , input_columns=[\"input_length\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:58:19.220692Z","iopub.execute_input":"2024-03-20T05:58:19.221009Z","iopub.status.idle":"2024-03-20T05:58:19.604009Z","shell.execute_reply.started":"2024-03-20T05:58:19.220983Z","shell.execute_reply":"2024-03-20T05:58:19.603166Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0ad19b60ed44ffe9ed472b633232967"}},"metadata":{}}]},{"cell_type":"code","source":"@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n\n    def __call__(\n        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n    ) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need different padding methods\n        # first treat the audio inputs by simply returning torch tensors\n        input_features = [\n            {\"input_features\": feature[\"input_features\"][0]} for feature in features\n        ]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        # get the tokenized label sequences\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        # pad the labels to max length\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(\n            labels_batch.attention_mask.ne(1), -100\n        )\n\n        # if bos token is appended in previous tokenization step,\n        # cut bos token here as it's append later anyways\n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:58:19.605335Z","iopub.execute_input":"2024-03-20T05:58:19.606124Z","iopub.status.idle":"2024-03-20T05:58:19.617099Z","shell.execute_reply.started":"2024-03-20T05:58:19.606090Z","shell.execute_reply":"2024-03-20T05:58:19.616262Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:58:19.618188Z","iopub.execute_input":"2024-03-20T05:58:19.618451Z","iopub.status.idle":"2024-03-20T05:58:19.630832Z","shell.execute_reply.started":"2024-03-20T05:58:19.618427Z","shell.execute_reply":"2024-03-20T05:58:19.630069Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"wer\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:58:19.631935Z","iopub.execute_input":"2024-03-20T05:58:19.632658Z","iopub.status.idle":"2024-03-20T05:58:20.595820Z","shell.execute_reply.started":"2024-03-20T05:58:19.632626Z","shell.execute_reply":"2024-03-20T05:58:20.595056Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15ee7fba2a31420593fb0d31c72b0e2b"}},"metadata":{}}]},{"cell_type":"code","source":"normalizer = BasicTextNormalizer()\n\ndef compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    # replace -100 with the pad_token_id\n    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n\n    # we do not want to group tokens when computing the metrics\n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n\n    # compute orthographic wer\n    wer_ortho = metric.compute(predictions=pred_str, references=label_str)\n\n    # compute normalised WER\n    pred_str_norm = [normalizer(pred) for pred in pred_str]\n    label_str_norm = [normalizer(label) for label in label_str]\n    # filtering step to only evaluate the samples that correspond to non-zero references:\n    pred_str_norm = [\n        pred_str_norm[i] for i in range(len(pred_str_norm)) if len(label_str_norm[i]) > 0\n    ]\n    label_str_norm = [\n        label_str_norm[i]\n        for i in range(len(label_str_norm))\n        if len(label_str_norm[i]) > 0\n    ]\n\n    wer = metric.compute(predictions=pred_str_norm, references=label_str_norm)\n\n    return {\"wer_ortho\": wer_ortho, \"wer\": wer}","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:58:20.596927Z","iopub.execute_input":"2024-03-20T05:58:20.597174Z","iopub.status.idle":"2024-03-20T05:58:20.605947Z","shell.execute_reply.started":"2024-03-20T05:58:20.597151Z","shell.execute_reply":"2024-03-20T05:58:20.605059Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = WhisperForConditionalGeneration.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:58:20.607139Z","iopub.execute_input":"2024-03-20T05:58:20.607417Z","iopub.status.idle":"2024-03-20T05:58:21.997744Z","shell.execute_reply.started":"2024-03-20T05:58:20.607394Z","shell.execute_reply":"2024-03-20T05:58:21.996860Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"088a4d77b8604d61b6aa47e9c3d97239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"675cc1f71dee497188cf7145da624cef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6a56127638e47dd85fcb878a6562616"}},"metadata":{}}]},{"cell_type":"code","source":"# disable cache during training since it's incompatible with gradient checkpointing\nmodel.config.use_cache = False\n\n# set language and task for generation and re-enable cache\nmodel.generate = partial(\n    model.generate, language=\"english\", task=\"transcribe\", use_cache=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:58:21.998935Z","iopub.execute_input":"2024-03-20T05:58:21.999220Z","iopub.status.idle":"2024-03-20T05:58:22.004185Z","shell.execute_reply.started":"2024-03-20T05:58:21.999195Z","shell.execute_reply":"2024-03-20T05:58:22.003000Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"name = model_name.split(\"/\")[-1]\nhf_dir = f\"{name}_finetuned_minds14_en-US\"\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=hf_dir,  # name on the HF Hub\n    auto_find_batch_size=True,\n    gradient_accumulation_steps=2,  # increase by 2x for every 2x decrease in batch size\n    learning_rate=5e-5,\n    warmup_ratio=0.1,\n    gradient_checkpointing=True,\n    fp16=True,\n    num_train_epochs=5,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    predict_with_generate=True,\n    generation_max_length=225,\n    logging_steps=5,\n    report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:13:22.730684Z","iopub.execute_input":"2024-03-20T06:13:22.731399Z","iopub.status.idle":"2024-03-20T06:13:22.738470Z","shell.execute_reply.started":"2024-03-20T06:13:22.731369Z","shell.execute_reply":"2024-03-20T06:13:22.737460Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=data[\"train\"],\n    eval_dataset=data[\"test\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:13:25.318782Z","iopub.execute_input":"2024-03-20T06:13:25.319550Z","iopub.status.idle":"2024-03-20T06:13:25.523848Z","shell.execute_reply.started":"2024-03-20T06:13:25.319517Z","shell.execute_reply":"2024-03-20T06:13:25.522935Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:13:29.149240Z","iopub.execute_input":"2024-03-20T06:13:29.149629Z","iopub.status.idle":"2024-03-20T06:24:44.127313Z","shell.execute_reply.started":"2024-03-20T06:13:29.149596Z","shell.execute_reply":"2024-03-20T06:24:44.126318Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [140/140 11:00, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer Ortho</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.014500</td>\n      <td>0.619593</td>\n      <td>0.305984</td>\n      <td>0.309327</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.008800</td>\n      <td>0.627827</td>\n      <td>0.328809</td>\n      <td>0.330579</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.007000</td>\n      <td>0.620184</td>\n      <td>0.330660</td>\n      <td>0.335301</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000900</td>\n      <td>0.614789</td>\n      <td>0.324491</td>\n      <td>0.329398</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000600</td>\n      <td>0.616766</td>\n      <td>0.326342</td>\n      <td>0.331759</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory whisper-tiny_finetuned_minds14_en-US/checkpoint-28 already exists and is non-empty. Saving will proceed but saved results may be invalid.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nCheckpoint destination directory whisper-tiny_finetuned_minds14_en-US/checkpoint-56 already exists and is non-empty. Saving will proceed but saved results may be invalid.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nCheckpoint destination directory whisper-tiny_finetuned_minds14_en-US/checkpoint-84 already exists and is non-empty. Saving will proceed but saved results may be invalid.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nCheckpoint destination directory whisper-tiny_finetuned_minds14_en-US/checkpoint-112 already exists and is non-empty. Saving will proceed but saved results may be invalid.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\nThere were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=140, training_loss=0.00911715037821393, metrics={'train_runtime': 664.9013, 'train_samples_per_second': 3.346, 'train_steps_per_second': 0.211, 'total_flos': 5.4777019392e+16, 'train_loss': 0.00911715037821393, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"kwargs = {\n    \"dataset_tags\": \"PolyAI/minds14\",\n    \"model_name\": hf_dir,\n    \"finetuned_from\": model_name,\n    \"tasks\": \"automatic-speech-recognition\",\n}","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:25:08.634764Z","iopub.execute_input":"2024-03-20T06:25:08.635601Z","iopub.status.idle":"2024-03-20T06:25:08.639909Z","shell.execute_reply.started":"2024-03-20T06:25:08.635570Z","shell.execute_reply":"2024-03-20T06:25:08.638995Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:25:10.752477Z","iopub.execute_input":"2024-03-20T06:25:10.753166Z","iopub.status.idle":"2024-03-20T06:25:15.163183Z","shell.execute_reply.started":"2024-03-20T06:25:10.753133Z","shell.execute_reply":"2024-03-20T06:25:15.162319Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1710915210.223e8173d876.34.1:   0%|          | 0.00/14.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e2001e9cbfe4f5181616cffc8336bf0"}},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/jaymanvirk/whisper-tiny_finetuned_minds14_en-US/commit/bdd3a4606d42f2fe52c67337e88ae0b55bab4627', commit_message='End of training', commit_description='', oid='bdd3a4606d42f2fe52c67337e88ae0b55bab4627', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}